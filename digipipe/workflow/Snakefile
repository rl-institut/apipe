"""
Snakemake file for digipipe
"""

from snakemake.utils import min_version
min_version("6.0")

from digipipe.scripts.config import load_dataset_configs
from digipipe.scripts.data_io import *
from digipipe.store.utils import get_abs_dataset_path, get_abs_store_root_path
from digipipe.config import GLOBAL_CONFIG

config = GLOBAL_CONFIG
config.update(load_dataset_configs())

# include store modules
include: "../store/preprocessed/module.smk"
include: "../store/datasets/module.smk"

# ===== RULES =====

rule all:
    input:
        forests=rules.datasets_osm_forest_extract_tags.output,
        muns=rules.datasets_bkg_vg250_muns_region_create.output,
        districts=rules.datasets_bkg_vg250_districts_region_create.output,
        region=rules.datasets_bkg_vg250_region_create.output,
        wind=rules.datasets_bnetza_mastr_wind_region_create.output,
        pv_ground=rules.datasets_bnetza_mastr_pv_ground_region_create.output,
        pv_roof=rules.datasets_bnetza_mastr_pv_roof_region_create.output,
        biomass=rules.datasets_bnetza_mastr_biomass_region_create.output,
        hydro=rules.datasets_bnetza_mastr_hydro_region_create.output,
        combustion=rules.datasets_bnetza_mastr_combustion_region_create.output,
        mastr_names=rules.datasets_bnetza_mastr_captions_create.output,
        gsgk=rules.datasets_bnetza_mastr_gsgk_region_create.output,
        storage=rules.datasets_bnetza_mastr_storage_region_create.output,
        population=rules.datasets_population_region_create.output,
        demand_hh_ts=rules.datasets_demand_electricity_region_hh_normalize_timeseries.output,
        demand_hh_con=rules.datasets_demand_electricity_region_hh_merge_demand_years.output,
        demand_cts_ts=rules.datasets_demand_electricity_region_cts_normalize_timeseries.output,
        demand_cts_con=rules.datasets_demand_electricity_region_cts_merge_demand_years.output,
        demand_ind_ts=rules.datasets_demand_electricity_region_ind_normalize_timeseries.output,
        demand_ind_con=rules.datasets_demand_electricity_region_ind_merge_demand_years.output,
    # run:
    #     print("CONFIG MAIN:")
    #     print(config)
    #     print(workflow.basedir)

rule clean:
    """
    Remove all output and temporary files.
    """
    params:
        preprocessed=expand(
            get_abs_dataset_path("preprocessed", "{name}", data_dir=True) / "*",
            name=config.get("store")["preprocessed"].keys()
        ),
        preprocessed_logging = get_abs_dataset_path("preprocessed", ".log", data_dir=False) / "*",
        datasets=expand(
            get_abs_dataset_path("datasets", "{name}", data_dir=True) / "*",
            name=config.get("store")["datasets"].keys()
        ),
        datasets_logging = get_abs_dataset_path("datasets", ".log", data_dir=False) / "*",
    shell:
        """
        rm -f {params.preprocessed}
        rm -f {params.preprocessed_logging}
        rm -f {params.datasets}
        rm -f {params.datasets_logging}
        """


rule download_raw_zip:
    """
    Downloads zipfile from the cloud containing the raw data and stores it in 'store/temp'
    """
    output:
        raw_zip=get_abs_store_root_path() / "temp" / "raw.zip"
    params:
        url=config["global"]["input_data"]["download_url"]
    run:
        try:
            download_file(params.url, output.raw_zip)
        except Exception as e:
            raise RuntimeError(f"Error downloading file from {params.url}: {e}")



rule update_raw:
    """
    Extracts 'raw.zip' and copies containing folders to 'store/raw'
    """
    input:
        raw_zip=get_abs_store_root_path() / "temp" / "raw.zip"
    params:
        temp_dir=get_abs_store_root_path() / "temp",
        raw_dir=get_abs_store_root_path() / "raw",
        temp_raw_dir=get_abs_store_root_path() / "temp" / "store" / "raw"
    run:
        try:
            extract_zipfile(input.raw_zip, params.temp_dir)
            copy_files(params.temp_raw_dir, params.raw_dir)
            clean_folder(params.temp_dir)
        except Exception as e:
            raise RuntimeError(f"Error updating raw data: {e}")
