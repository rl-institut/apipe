"""
Snakemake file for digipipe
"""

from snakemake.utils import min_version
min_version("6.0")

from digipipe.scripts.config import load_dataset_configs
from digipipe.store.utils import get_abs_dataset_path
from digipipe.config import GLOBAL_CONFIG

config = GLOBAL_CONFIG
config.update(load_dataset_configs())

# Path to esys appdata
APPDATA_ESYS_PATH = get_abs_dataset_path("appdata", "esys")

# Include store modules
include: "../store/preprocessed/module.smk"
include: "../store/datasets/module.smk"

# Include esys snakefiles
include: "../esys/Snakefile"


# ===== RULES =====

rule all:
    input:
        forests=rules.datasets_osm_forest_extract_tags.output,
        muns=rules.datasets_bkg_vg250_muns_region_create.output,
        districts=rules.datasets_bkg_vg250_districts_region_create.output,
        region=rules.datasets_bkg_vg250_region_create.output,
        wind=rules.datasets_bnetza_mastr_wind_region_create.output,
        pv_ground=rules.datasets_bnetza_mastr_pv_ground_region_create.output,
        pv_roof=rules.datasets_bnetza_mastr_pv_roof_region_create.output,
        biomass=rules.datasets_bnetza_mastr_biomass_region_create.output,
        hydro=rules.datasets_bnetza_mastr_hydro_region_create.output,
        combustion=rules.datasets_bnetza_mastr_combustion_region_create.output,
        mastr_names=rules.datasets_bnetza_mastr_captions_create.output,
        gsgk=rules.datasets_bnetza_mastr_gsgk_region_create.output,
        storage=rules.datasets_bnetza_mastr_storage_region_create.output,
        population=rules.datasets_population_create.output,
        esys_appdata=rules.make_esys_appdata.output
    # run:
    #     print("CONFIG MAIN:")
    #     print(config)
    #     print(workflow.basedir)

rule clean:
    """
    Remove all output and temporary files.
    """
    params:
        preprocessed=expand(
            get_abs_dataset_path("preprocessed", "{name}", data_dir=True) / "*",
            name=config.get("store")["preprocessed"].keys()
        ),
        datasets=expand(
            get_abs_dataset_path("datasets", "{name}", data_dir=True) / "*",
            name=config.get("store")["datasets"].keys()
        )
    shell:
        """
        rm -f {params.preprocessed}
        rm -f {params.datasets}

        # Check if there are subdirectories in appdata esys dir
        if [ "$(find {APPDATA_ESYS_PATH} -mindepth 1 -type d)" ]; then
          rm -r {APPDATA_ESYS_PATH}/*
        fi
        echo "Removed all preprocessed data in directories: preprocessed, datasets and appdata."
        """
